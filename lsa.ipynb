{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSA and Textual Coherence\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constant Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to directory containing preprocessed COCA files\n",
    "COCA_PREPROC_DIR = Path(\"/Volumes/Elements/Capstone/coca-preproc-spacy/\")\n",
    "\n",
    "# Path to directory containing preprocessed Elsevier files\n",
    "ELSEVIER_PREPROC_DIR = Path(\"/Volumes/Elements/Capstone/elsevier-preproc-spacy/\")\n",
    "\n",
    "# Path to file containing all subject areas\n",
    "SUBJAREAS = Path(\"./subjareas.txt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSA and Cosine Similarity\n",
    "We first create an LSA matrix for each corpus with sentences as the unit of analysis in the term-document matrix. Then, we calculate the average cosine similarity between adjoining sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download stopwords to filter out\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "stopwords = nlp.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lsa_vector_space(articles, text_key, components = 100):\n",
    "    \"\"\"\n",
    "    Given a list of articles, return an LSA vector space trained on all the articles.\n",
    "\n",
    "    Args:\n",
    "    articles: A set of preprocessed articles.\n",
    "    text_key: A string describing the key for where body text is stored for each \n",
    "    article object. \n",
    "    components: An integer describing how many components the final vector space should \n",
    "    have.\n",
    "    \"\"\"\n",
    "\n",
    "    text_data = [\n",
    "        \" \".join([token.text.lower() for token in sentence if token.text.lower() not in stopwords])\n",
    "        for text in articles for sentence in text[text_key]\n",
    "    ]\n",
    "\n",
    "    \n",
    "    filtered_data = [text for text in text_data if text]\n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(filtered_data)\n",
    "\n",
    "    if X.shape[1] <= components:\n",
    "        return np.nan\n",
    "\n",
    "    lsa = TruncatedSVD(n_components=components)\n",
    "    lsa_matrix = lsa.fit_transform(X)\n",
    "\n",
    "    return lsa_matrix\n",
    "\n",
    "def doc_sentence_cosine_sim(articles, text_key, components = 100):\n",
    "    \"\"\"\n",
    "    Given a set of prerocessed articles, train an LSA matrix on the sentences of the articles and\n",
    "    return the average distance between adjoining sentences in each document. \n",
    "\n",
    "    Args:\n",
    "    articles: A set of preprocessed articles.\n",
    "    text_key: A string describing the key for where body text is stored for each \n",
    "    article object. \n",
    "    components: An integer describing how many components the final vector space should \n",
    "    have.\n",
    "    \"\"\"\n",
    "\n",
    "    vector_space = lsa_vector_space(articles, text_key, components)\n",
    "    cosine_similarities = []\n",
    "\n",
    "    for index, article in enumerate(articles):\n",
    "        start_index = sum(len(sentences) for sentences in articles[:index])\n",
    "        end_index = start_index + len(article)\n",
    "\n",
    "        article_cosine_similarity = [\n",
    "            cosine_similarity(vector_space[i].reshape(1, -1), vector_space[i+1].reshape(1, -1)) \n",
    "            for i in range(start_index, end_index-1)\n",
    "            ]\n",
    "        \n",
    "        cosine_similarities.append(np.mean(article_cosine_similarity))\n",
    "\n",
    "    avg_document_sim = np.mean(cosine_similarities)\n",
    "    \n",
    "    return avg_document_sim\n",
    "\n",
    "def bootstrap_lsa_cosine_sim(\n",
    "        subj_articles,\n",
    "        components = 100,\n",
    "        num_resamples=300, \n",
    "        alpha=0.05, \n",
    "        ):\n",
    "    \"\"\"\n",
    "    Bootstrap the vector cosine similarity procedure to generate an average cosine similarity\n",
    "    with confidence intervals.\n",
    "\n",
    "    Args:\n",
    "    subj_articles: Preprocessed articles from a specific discipline in the \n",
    "    ElSevier OA CC-BY corpus.\n",
    "    components: The number of components in the LSA matrix. Default = 100.. \n",
    "    item in contains the word vector for that token in the COCA embedding space.\n",
    "    num_resamples: The number of iterations for bootstrapping. Default = 300.\n",
    "    alpha: The alpha value for which to calculate the confidence intervals. Default = 0.05.\n",
    "    \"\"\"\n",
    "    average_doc_sentence_cosine_sim = []\n",
    "    n = len(subj_articles)\n",
    "\n",
    "    for i in range(num_resamples):\n",
    "        resampled_texts = np.random.choice(subj_articles, size=n, replace=True)\n",
    "\n",
    "        sample_doc_sentence_sim = doc_sentence_cosine_sim(resampled_texts, \"body_text_docs\", components)\n",
    "\n",
    "        average_doc_sentence_cosine_sim.append(sample_doc_sentence_sim)\n",
    "\n",
    "    average_sim = np.mean(average_doc_sentence_cosine_sim)\n",
    "    ci_lower = np.percentile(average_doc_sentence_cosine_sim, alpha/2 * 100)\n",
    "    ci_upper = np.percentile(average_doc_sentence_cosine_sim, (1 - alpha/2) * 100)\n",
    "\n",
    "    return average_sim, ci_lower, ci_upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average similarity\n",
    "with open(f'{COCA_PREPROC_DIR}/2015.pickle', 'rb') as f:\n",
    "    coca = pickle.load(f)\n",
    "\n",
    "coca_sentence_sim = doc_sentence_cosine_sim(coca, \"text_docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.846109002"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average cosine similarity between adjoining sentences in COCA texts\n",
    "coca_sentence_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define dataframe to store results\n",
    "avg_sentence_cosine_sim_df = pd.DataFrame(columns=['subj', 'avg', 'lower CI', 'upper CI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{SUBJAREAS}', 'r') as subj_list_file:\n",
    "    for subject in subj_list_file:\n",
    "        subject = subject.strip()\n",
    "        print(subject)\n",
    "\n",
    "        with open(f'{ELSEVIER_PREPROC_DIR}/{subject}.pickle', 'rb') as articles_file:\n",
    "            articles = pickle.load(articles_file)\n",
    "\n",
    "        bootstrap_avg_sentence_cosine_sim = bootstrap_lsa_cosine_sim(articles)\n",
    "        subject_row = {\n",
    "            'subj': subject, \n",
    "            'avg': bootstrap_avg_sentence_cosine_sim[0], \n",
    "            'lower CI': bootstrap_avg_sentence_cosine_sim[1], \n",
    "            'upper CI': bootstrap_avg_sentence_cosine_sim[2]\n",
    "        }\n",
    "\n",
    "        avg_sentence_cosine_sim_df = avg_sentence_cosine_sim_df.append(subject_row, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subj</th>\n",
       "      <th>avg</th>\n",
       "      <th>lower CI</th>\n",
       "      <th>upper CI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EART</td>\n",
       "      <td>0.819450</td>\n",
       "      <td>0.813939</td>\n",
       "      <td>0.822223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AGRI</td>\n",
       "      <td>0.832435</td>\n",
       "      <td>0.825399</td>\n",
       "      <td>0.836324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NEUR</td>\n",
       "      <td>0.835997</td>\n",
       "      <td>0.834347</td>\n",
       "      <td>0.840682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PHAR</td>\n",
       "      <td>0.836817</td>\n",
       "      <td>0.836607</td>\n",
       "      <td>0.841495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ARTS</td>\n",
       "      <td>0.838128</td>\n",
       "      <td>0.832263</td>\n",
       "      <td>0.845061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ENER</td>\n",
       "      <td>0.838245</td>\n",
       "      <td>0.834876</td>\n",
       "      <td>0.839705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PSYC</td>\n",
       "      <td>0.838533</td>\n",
       "      <td>0.837942</td>\n",
       "      <td>0.840018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MATE</td>\n",
       "      <td>0.839185</td>\n",
       "      <td>0.829291</td>\n",
       "      <td>0.845111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DENT</td>\n",
       "      <td>0.839496</td>\n",
       "      <td>0.832304</td>\n",
       "      <td>0.844269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ENGI</td>\n",
       "      <td>0.839678</td>\n",
       "      <td>0.834717</td>\n",
       "      <td>0.843212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BUSI</td>\n",
       "      <td>0.839773</td>\n",
       "      <td>0.830696</td>\n",
       "      <td>0.845918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ENVI</td>\n",
       "      <td>0.841947</td>\n",
       "      <td>0.833349</td>\n",
       "      <td>0.845212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SOCI</td>\n",
       "      <td>0.843321</td>\n",
       "      <td>0.840610</td>\n",
       "      <td>0.850557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DECI</td>\n",
       "      <td>0.843332</td>\n",
       "      <td>0.839818</td>\n",
       "      <td>0.851891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CENG</td>\n",
       "      <td>0.843481</td>\n",
       "      <td>0.839134</td>\n",
       "      <td>0.843821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CHEM</td>\n",
       "      <td>0.846389</td>\n",
       "      <td>0.836704</td>\n",
       "      <td>0.854775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ECON</td>\n",
       "      <td>0.846982</td>\n",
       "      <td>0.840179</td>\n",
       "      <td>0.854650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>COMP</td>\n",
       "      <td>0.848567</td>\n",
       "      <td>0.840087</td>\n",
       "      <td>0.849304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>IMMU</td>\n",
       "      <td>0.850003</td>\n",
       "      <td>0.841503</td>\n",
       "      <td>0.858172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>HEAL</td>\n",
       "      <td>0.850061</td>\n",
       "      <td>0.849491</td>\n",
       "      <td>0.855560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>VETE</td>\n",
       "      <td>0.851302</td>\n",
       "      <td>0.848290</td>\n",
       "      <td>0.855110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PHYS</td>\n",
       "      <td>0.853166</td>\n",
       "      <td>0.850775</td>\n",
       "      <td>0.859314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NURS</td>\n",
       "      <td>0.855807</td>\n",
       "      <td>0.849941</td>\n",
       "      <td>0.864557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>MEDI</td>\n",
       "      <td>0.857314</td>\n",
       "      <td>0.849853</td>\n",
       "      <td>0.865531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BIOC</td>\n",
       "      <td>0.858417</td>\n",
       "      <td>0.856752</td>\n",
       "      <td>0.861806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>MATH</td>\n",
       "      <td>0.868773</td>\n",
       "      <td>0.862401</td>\n",
       "      <td>0.872907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    subj       avg  lower CI  upper CI\n",
       "0   EART  0.819450  0.813939  0.822223\n",
       "1   AGRI  0.832435  0.825399  0.836324\n",
       "2   NEUR  0.835997  0.834347  0.840682\n",
       "3   PHAR  0.836817  0.836607  0.841495\n",
       "4   ARTS  0.838128  0.832263  0.845061\n",
       "5   ENER  0.838245  0.834876  0.839705\n",
       "6   PSYC  0.838533  0.837942  0.840018\n",
       "7   MATE  0.839185  0.829291  0.845111\n",
       "8   DENT  0.839496  0.832304  0.844269\n",
       "9   ENGI  0.839678  0.834717  0.843212\n",
       "10  BUSI  0.839773  0.830696  0.845918\n",
       "11  ENVI  0.841947  0.833349  0.845212\n",
       "12  SOCI  0.843321  0.840610  0.850557\n",
       "13  DECI  0.843332  0.839818  0.851891\n",
       "14  CENG  0.843481  0.839134  0.843821\n",
       "15  CHEM  0.846389  0.836704  0.854775\n",
       "16  ECON  0.846982  0.840179  0.854650\n",
       "17  COMP  0.848567  0.840087  0.849304\n",
       "18  IMMU  0.850003  0.841503  0.858172\n",
       "19  HEAL  0.850061  0.849491  0.855560\n",
       "20  VETE  0.851302  0.848290  0.855110\n",
       "21  PHYS  0.853166  0.850775  0.859314\n",
       "22  NURS  0.855807  0.849941  0.864557\n",
       "23  MEDI  0.857314  0.849853  0.865531\n",
       "24  BIOC  0.858417  0.856752  0.861806\n",
       "25  MATH  0.868773  0.862401  0.872907"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Metrics by subject\n",
    "avg_sentence_cosine_sim_df.sort_values(by= \"avg\", ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subj</th>\n",
       "      <th>avg</th>\n",
       "      <th>lower CI</th>\n",
       "      <th>upper CI</th>\n",
       "      <th>COCA distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHEM</td>\n",
       "      <td>0.846389</td>\n",
       "      <td>0.836704</td>\n",
       "      <td>0.854775</td>\n",
       "      <td>0.000280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ECON</td>\n",
       "      <td>0.846982</td>\n",
       "      <td>0.840179</td>\n",
       "      <td>0.854650</td>\n",
       "      <td>0.000873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COMP</td>\n",
       "      <td>0.848567</td>\n",
       "      <td>0.840087</td>\n",
       "      <td>0.849304</td>\n",
       "      <td>0.002458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CENG</td>\n",
       "      <td>0.843481</td>\n",
       "      <td>0.839134</td>\n",
       "      <td>0.843821</td>\n",
       "      <td>0.002628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DECI</td>\n",
       "      <td>0.843332</td>\n",
       "      <td>0.839818</td>\n",
       "      <td>0.851891</td>\n",
       "      <td>0.002777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SOCI</td>\n",
       "      <td>0.843321</td>\n",
       "      <td>0.840610</td>\n",
       "      <td>0.850557</td>\n",
       "      <td>0.002788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>IMMU</td>\n",
       "      <td>0.850003</td>\n",
       "      <td>0.841503</td>\n",
       "      <td>0.858172</td>\n",
       "      <td>0.003894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HEAL</td>\n",
       "      <td>0.850061</td>\n",
       "      <td>0.849491</td>\n",
       "      <td>0.855560</td>\n",
       "      <td>0.003952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ENVI</td>\n",
       "      <td>0.841947</td>\n",
       "      <td>0.833349</td>\n",
       "      <td>0.845212</td>\n",
       "      <td>0.004163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>VETE</td>\n",
       "      <td>0.851302</td>\n",
       "      <td>0.848290</td>\n",
       "      <td>0.855110</td>\n",
       "      <td>0.005193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BUSI</td>\n",
       "      <td>0.839773</td>\n",
       "      <td>0.830696</td>\n",
       "      <td>0.845918</td>\n",
       "      <td>0.006336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ENGI</td>\n",
       "      <td>0.839678</td>\n",
       "      <td>0.834717</td>\n",
       "      <td>0.843212</td>\n",
       "      <td>0.006431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DENT</td>\n",
       "      <td>0.839496</td>\n",
       "      <td>0.832304</td>\n",
       "      <td>0.844269</td>\n",
       "      <td>0.006613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MATE</td>\n",
       "      <td>0.839185</td>\n",
       "      <td>0.829291</td>\n",
       "      <td>0.845111</td>\n",
       "      <td>0.006924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PHYS</td>\n",
       "      <td>0.853166</td>\n",
       "      <td>0.850775</td>\n",
       "      <td>0.859314</td>\n",
       "      <td>0.007057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PSYC</td>\n",
       "      <td>0.838533</td>\n",
       "      <td>0.837942</td>\n",
       "      <td>0.840018</td>\n",
       "      <td>0.007576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ENER</td>\n",
       "      <td>0.838245</td>\n",
       "      <td>0.834876</td>\n",
       "      <td>0.839705</td>\n",
       "      <td>0.007864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ARTS</td>\n",
       "      <td>0.838128</td>\n",
       "      <td>0.832263</td>\n",
       "      <td>0.845061</td>\n",
       "      <td>0.007981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PHAR</td>\n",
       "      <td>0.836817</td>\n",
       "      <td>0.836607</td>\n",
       "      <td>0.841495</td>\n",
       "      <td>0.009292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NURS</td>\n",
       "      <td>0.855807</td>\n",
       "      <td>0.849941</td>\n",
       "      <td>0.864557</td>\n",
       "      <td>0.009698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NEUR</td>\n",
       "      <td>0.835997</td>\n",
       "      <td>0.834347</td>\n",
       "      <td>0.840682</td>\n",
       "      <td>0.010112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MEDI</td>\n",
       "      <td>0.857314</td>\n",
       "      <td>0.849853</td>\n",
       "      <td>0.865531</td>\n",
       "      <td>0.011205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BIOC</td>\n",
       "      <td>0.858417</td>\n",
       "      <td>0.856752</td>\n",
       "      <td>0.861806</td>\n",
       "      <td>0.012308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>AGRI</td>\n",
       "      <td>0.832435</td>\n",
       "      <td>0.825399</td>\n",
       "      <td>0.836324</td>\n",
       "      <td>0.013674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>MATH</td>\n",
       "      <td>0.868773</td>\n",
       "      <td>0.862401</td>\n",
       "      <td>0.872907</td>\n",
       "      <td>0.022664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>EART</td>\n",
       "      <td>0.819450</td>\n",
       "      <td>0.813939</td>\n",
       "      <td>0.822223</td>\n",
       "      <td>0.026659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    subj       avg  lower CI  upper CI  COCA distance\n",
       "0   CHEM  0.846389  0.836704  0.854775       0.000280\n",
       "1   ECON  0.846982  0.840179  0.854650       0.000873\n",
       "2   COMP  0.848567  0.840087  0.849304       0.002458\n",
       "3   CENG  0.843481  0.839134  0.843821       0.002628\n",
       "4   DECI  0.843332  0.839818  0.851891       0.002777\n",
       "5   SOCI  0.843321  0.840610  0.850557       0.002788\n",
       "6   IMMU  0.850003  0.841503  0.858172       0.003894\n",
       "7   HEAL  0.850061  0.849491  0.855560       0.003952\n",
       "8   ENVI  0.841947  0.833349  0.845212       0.004163\n",
       "9   VETE  0.851302  0.848290  0.855110       0.005193\n",
       "10  BUSI  0.839773  0.830696  0.845918       0.006336\n",
       "11  ENGI  0.839678  0.834717  0.843212       0.006431\n",
       "12  DENT  0.839496  0.832304  0.844269       0.006613\n",
       "13  MATE  0.839185  0.829291  0.845111       0.006924\n",
       "14  PHYS  0.853166  0.850775  0.859314       0.007057\n",
       "15  PSYC  0.838533  0.837942  0.840018       0.007576\n",
       "16  ENER  0.838245  0.834876  0.839705       0.007864\n",
       "17  ARTS  0.838128  0.832263  0.845061       0.007981\n",
       "18  PHAR  0.836817  0.836607  0.841495       0.009292\n",
       "19  NURS  0.855807  0.849941  0.864557       0.009698\n",
       "20  NEUR  0.835997  0.834347  0.840682       0.010112\n",
       "21  MEDI  0.857314  0.849853  0.865531       0.011205\n",
       "22  BIOC  0.858417  0.856752  0.861806       0.012308\n",
       "23  AGRI  0.832435  0.825399  0.836324       0.013674\n",
       "24  MATH  0.868773  0.862401  0.872907       0.022664\n",
       "25  EART  0.819450  0.813939  0.822223       0.026659"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Metrics with distance to COCA average included\n",
    "avg_sentence_cosine_sim_df[\"COCA distance\"] = avg_sentence_cosine_sim_df[\"avg\"].sub(coca_sentence_sim).abs()\n",
    "avg_sentence_cosine_sim_df.sort_values(by=\"COCA distance\", ignore_index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ewiser",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
